{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "import settings\n",
    "import time\n",
    "\n",
    "def db_connect():\n",
    "    \"\"\"\n",
    "    Performs database connection using database settings from settings.py.\n",
    "    Returns sqlalchemy engine instance\n",
    "    \"\"\"\n",
    "    return create_engine(URL(**settings.DATABASE))\n",
    "\n",
    "db = db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in list of icustay_ids\n",
    "df = pd.read_csv('icustay_list.csv', names = ['icustay_id'])\n",
    "ids = list(df.icustay_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#populate new w_tables\n",
    "populate_wtables(ids, chart_tables, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build new csvs with all itemids and correct icustay_ids\n",
    "get_itemid_sum(w_chart_tables, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make df out of all w_chartevent csv files\n",
    "import glob\n",
    "filenames=glob.glob('w_chartevents_*')\n",
    "dflist=[]\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(filename, index_col = 0)\n",
    "    dflist.append(df)\n",
    "\n",
    "chart_df = pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull the d_items database (prepping to join to chart_df)\n",
    "que = '''select * from d_items'''\n",
    "d_items_df = pd.read_sql(que, db)\n",
    "\n",
    "#joining the df\n",
    "feat_df = chart_df.merge(d_items_df[['itemid', 'label']], on='itemid')\n",
    "\n",
    "#making the ratio \n",
    "feat_df['ratio'] = feat_df.num_patients/18000\n",
    "\n",
    "feat_df.sort_values(by='num_patients', ascending = False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3167"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing itemids in feat_df vs. itemids in keep list \n",
    "\n",
    "keep_items = pd.read_csv('Keep_items.txt', names = ['itemsid'])\n",
    "keep_set = set(keep_items.itemsid.values)\n",
    "all_set = set(feat_df.itemid.values)\n",
    "cut_set = all_set.difference(keep_set)\n",
    "len(cut_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#query itemid + distinct number of patients that itemid has been applied to\n",
    "#save the query result in a csv file \n",
    "import time\n",
    "#time.sleep(60*60) this was to give sam's query an hour to run\n",
    "def get_itemid_sum(chart_tables, db):\n",
    "    import time\n",
    "    for chart in chart_tables:\n",
    "        filename = chart + '.csv'\n",
    "        start = time.time()\n",
    "        que = '''select itemid, count(distinct subject_id) as num_patients\n",
    "                from %s \n",
    "                group by itemid ''' % chart\n",
    "        df = pd.read_sql(que, db)\n",
    "        df.to_csv(filename)\n",
    "        print(chart)\n",
    "        print(time.time()-start)\n",
    "        df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_wtables(ids, ref_tables, db):\n",
    "    from sqlalchemy import text\n",
    "    import time\n",
    "    #first, check to make sure all tables are empty. if not, break!\n",
    "    for table in ref_tables:\n",
    "        w_table = \"w_\" + table\n",
    "        #print(w_table)\n",
    "        que = '''select * from %s limit 5''' % w_table\n",
    "        df = pd.read_sql(que, db)\n",
    "        assert(len(df) < 1), \"Table %s is not empty!\" % w_table\n",
    "    \n",
    "\n",
    "    #okay, tables are empty and ready for population!\n",
    "    #loop through every table\n",
    "        #in each table, copy ids from \n",
    "    for table in ref_tables:\n",
    "        start_time = time.time()\n",
    "        for icu_id in ids:\n",
    "            w_table = \"w_\" + table\n",
    "            command =  '''INSERT INTO %s select * from %s where icustay_id = %d'''% (w_table, table, icu_id)\n",
    "            sql = text(command)\n",
    "            db.execute(sql)\n",
    "        print(table)\n",
    "        print(time.time()-start_time)\n",
    "'''\n",
    "#### Function 1 - Create new tables, scraping ICU IDs\n",
    "\n",
    "idea:\n",
    "    given ICUSTAYIDs, POPULATE new chartevent tables ONLY with those (scrape out babies and dead people)\n",
    "    CHECK IF DB EXISTS, IF SO BREAK\n",
    "\n",
    "input:\n",
    "    ICUSTAYIDs, db, chartables\n",
    "    (db to make sure we dont fuck this up)\n",
    "\n",
    "do:\n",
    "    for table in chart_tables:\n",
    "        for id in ICUSTAYIDs:\n",
    "            insert into w_chartevents_1 select * from chartevents_1 where icustay_id = 2873\n",
    "\n",
    "output:\n",
    "    returns nothing, just runs sql code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "##### Function 1.5 - Create new tables \n",
    "idea:\n",
    "    create new tables, chartevents_1-14, using same schema. DO NOT POPULATE, ONLY CREATE\n",
    "input:\n",
    "    list of old table names\n",
    "    db\n",
    "do:\n",
    "    for table in table names:\n",
    "        create new table w/ same schema, name is changed to w_(oldname)\n",
    "'''\n",
    "\n",
    "def spawn_wtables(old_tables, db):\n",
    "    from sqlalchemy import text\n",
    "    for table in old_tables:\n",
    "        new_table = 'w_' + table\n",
    "        command = '''create table %s as select * from %s where 1=0''' % (new_table, table)\n",
    "        sql = text(command)\n",
    "        db.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_chartevents_1',\n",
       " 'w_chartevents_10',\n",
       " 'w_chartevents_11',\n",
       " 'w_chartevents_12',\n",
       " 'w_chartevents_13',\n",
       " 'w_chartevents_14',\n",
       " 'w_chartevents_2',\n",
       " 'w_chartevents_3',\n",
       " 'w_chartevents_4',\n",
       " 'w_chartevents_5',\n",
       " 'w_chartevents_6',\n",
       " 'w_chartevents_7',\n",
       " 'w_chartevents_8',\n",
       " 'w_chartevents_9']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build new SQL tables\n",
    "\n",
    "#get list of all tables in db\n",
    "from sqlalchemy import MetaData\n",
    "start_time = time.time()\n",
    "m = MetaData(bind=db)\n",
    "m.reflect()\n",
    "tables = list(m.tables.keys())\n",
    "time.time()-start_time\n",
    "\n",
    "# from list of tables, get all chartevent tables\n",
    "import re\n",
    "tab_re = re.compile(r'^(w_chartevents_.*)')\n",
    "chart_tables = []\n",
    "for table in tables:\n",
    "    name=re.findall(tab_re, table)\n",
    "    if name:\n",
    "        chart_tables.append(name[0])\n",
    "w_chart_tables = sorted(chart_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items_dict = bin_itemids(ids, 'w_chartevents_')\n",
    "items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_chartevents_10\n",
      "1.7301506996154785\n",
      "w_chartevents_2\n",
      "53.15837121009827\n",
      "w_chartevents_5\n",
      "187.84087920188904\n",
      "w_chartevents_9\n",
      "0.028972387313842773\n"
     ]
    }
   ],
   "source": [
    "del_itemids(list(cut_set), 'w_chartevents_', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def del_itemids(ids, base_name, db):\n",
    "    import time\n",
    "    '''Takes list of itemids, base chart name, and db. Deletes all itemids from respective tables in db.'''\n",
    "    items_dict = bin_itemids(ids, base_name)\n",
    "    for table, ids in items_dict.items():\n",
    "        start_time=time.time()\n",
    "        for item_id in ids:\n",
    "            command =  '''DELETE FROM %s WHERE itemid = %d'''% (table, item_id)\n",
    "            sql = text(command)\n",
    "            db.execute(sql)\n",
    "        print(table)\n",
    "        print(time.time()-start_time)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_itemids(ids, base_name):\n",
    "    '''Takes a list of itemids, bin itemids into their respective chart based on base_name, output dictionary'''\n",
    "    items_dict = {}\n",
    "    items_index = [210,250,614,640,742,1800,2700,3700,4700,6000,7000,8000,220074,323769]\n",
    "    for index, item_bin in enumerate(items_index):\n",
    "        chart = base_name + str(index+1)\n",
    "        binned_ids = [i for i in ids if i < item_bin]\n",
    "        items_dict[chart] = binned_ids\n",
    "        ids = [i for i in ids if i not in binned_ids]\n",
    "    return items_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check amount of unique patients w_chartevents \n",
    "dflist=[]\n",
    "for table in w_chart_tables:\n",
    "    start_time=time.time()\n",
    "    command =  '''select distinct subject_id from %s''' % table\n",
    "    sql = text(command)\n",
    "    dflist.append(pd.read_sql(sql, db))\n",
    "    print(time.time()-start_time)\n",
    "df=pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_builder():\n",
    "    '''Takes list of itemids\n",
    "        bucket itemids\n",
    "        create new table with icustay + itemids as columns\n",
    "        \n",
    "        build data one patient at a time\n",
    "        for \n",
    "        for chart, itemids in itembuck:    \n",
    "            for item in itemids:\n",
    "                get all measurements + dates\n",
    "                put into dictionary\n",
    "            put dictionary into df\n",
    "        return df\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_wchart_columns(tables, columns):\n",
    "    '''takes list of columns and drops them from every table in tables'''\n",
    "    for table in tables:\n",
    "        start_time = time.time()\n",
    "        for column in columns:\n",
    "            command =  '''ALTER TABLE %s DROP %s'''% (table, column)\n",
    "            sql = text(command)\n",
    "            db.execute(sql)\n",
    "        print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadm_id', 'cgid', 'warning', 'stopped', 'resultstatus', 'error']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['hadm_id',\n",
    "'cgid',\n",
    "'warning',\n",
    "'stopped',\n",
    "'resultstatus',\n",
    "'error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wchart_data(tables, db):\n",
    "    '''Gets all tables in list from sql server'''\n",
    "    dflist = []\n",
    "    for table in tables:\n",
    "        start_time = time.time()\n",
    "        command =  '''select * from %s''' % table\n",
    "        sql = text(command)\n",
    "        dflist.append(pd.read_sql(sql, db))\n",
    "        print(table)\n",
    "        print(time.time()-start_time)\n",
    "    df = pd.concat(dflist)\n",
    "    print('Writing to pickle...')\n",
    "    df.to_pickle('w_chartevents.p')\n",
    "    dflist = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything below here is purely testing/development, should be taken as bad code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_wchart(df):\n",
    "'''\n",
    "after getting all w_charts into pandas:\n",
    "build features!\n",
    "'''\n",
    "    superdict = {}\n",
    "    for icustay_id in df.icustay_id.unique():\n",
    "        for itemid in df.itemid.unique():\n",
    "            create dict w/ every item\n",
    "            superdict['patient'].append(item)\n",
    "           \n",
    "    features_df = pd.dataframe(superdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icuid</th>\n",
       "      <th>itemid213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>[[2101-10-21 04:00:00, 3.0, points], [2101-10-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   icuid                                          itemid213\n",
       "0    123  [[2101-10-21 04:00:00, 3.0, points], [2101-10-..."
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdict = {'icuid':123}\n",
    "a = asdf[['charttime', 'valuenum', 'valueuom']].values.tolist()\n",
    "asdict['itemid213'] = [a]\n",
    "asdf2 = pd.DataFrame(asdict)\n",
    "asdf2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icuid</th>\n",
       "      <th>item1</th>\n",
       "      <th>item3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asd</td>\n",
       "      <td>[[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]</td>\n",
       "      <td>[[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  icuid                                         item1  \\\n",
       "0   asd  [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]   \n",
       "\n",
       "                                          item3  \n",
       "0  [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superdict={}\n",
    "superdict['icuid'] = 'asd'\n",
    "superdict['item1']  = [[[1, 2, 3], [1, 2,3], [1, 2, 3], [1, 2, 3]]]\n",
    "superdict['item3']  = [[[1, 2, 3], [1, 2,3], [1, 2, 3], [1, 2, 3]]]\n",
    "\n",
    "asdf2 = pd.DataFrame(superdict)\n",
    "asdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>icuid</th>\n",
       "      <th>item1</th>\n",
       "      <th>item3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>asd</td>\n",
       "      <td>[[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]</td>\n",
       "      <td>[[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 icuid                                         item1  \\\n",
       "0           0   asd  [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]   \n",
       "\n",
       "                                          item3  \n",
       "0  [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf2.to_csv('test.csv')\n",
    "asdf3 = pd.to_pickle('test.csv')\n",
    "asdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icuid</th>\n",
       "      <th>item1</th>\n",
       "      <th>item3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asd</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  icuid  item1                                         item3\n",
       "0   asd      2  [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_most_recent(entries):\n",
    "    '''Sort by time, return most recent data '''\n",
    "    sorted_entries = sorted(entries, key = lambda x: x[0])\n",
    "    return sorted_entries[-1][1]\n",
    "\n",
    "get_most_recent(entries)\n",
    "asdf2['item1'] = asdf2['item1'].apply(item_map['item1'])\n",
    "asdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_most_recent>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_map = {'item1' : get_most_recent}\n",
    "item_map['item1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = asdf[['charttime', 'valuenum', 'valuenum']].values.tolist()\n",
    "sorted(entries, key = lambda x: x[0])[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asdf[[['icustay_id']==211552]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
